{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch._dynamo\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "\n",
    "import rt1_model_v2 as rt1_model\n",
    "import rt1_dataset\n",
    "from utils_file import get_filename\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functools import reduce\n",
    "import importlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rt1_model' from '/home/user/Documents/projects/osil/rt1_model.py'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(rt1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._C._nn.scaled_dot_product_attention>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
    "torch.nn.functional.scaled_dot_product_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda torch.float32 <torch.amp.autocast_mode.autocast object at 0x7f69ef022e80>\n"
     ]
    }
   ],
   "source": [
    "# configuration\n",
    "\n",
    "# training config\n",
    "device='cuda'\n",
    "dtype = 'float32'\n",
    "\n",
    "# model\n",
    "n_layer: int = 6 # 12\n",
    "n_head: int = 8 # 12\n",
    "# n_embd = 768\n",
    "n_embd: int = 128\n",
    "dropout = 0.0 # for pretraining 0 is good, for finetuning try 0.1+\n",
    "bias = False # do we use bias inside LayerNorm and Linear layers?\n",
    "\n",
    "# data\n",
    "batch_size = 12 # if gradient_accumulation_steps > 1, this is the micro-batch size\n",
    "block_size = 1\n",
    "num_keyframes=5\n",
    "\n",
    "# torch\n",
    "seed_offset = 0\n",
    "torch.manual_seed(1337 + seed_offset) # TODO why 1337?\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "# note: float16 data type will automatically use a GradScaler\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "torch._dynamo.config.suppress_errors = False\n",
    "torch._dynamo.config.verbose=True\n",
    "print(device, ptdtype, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 1.36M\n"
     ]
    }
   ],
   "source": [
    "# Why does compile fail?\n",
    "# ImageFeatureEncoder\n",
    "# AttentionEncoderBlock\n",
    "# AttentionDecoderBlock\n",
    "model_args = dict(\n",
    "    n_layer=n_layer, \n",
    "    n_head=n_head, \n",
    "    n_embd=n_embd,\n",
    "    dropout=dropout, \n",
    "    bias=bias,\n",
    "    block_size_key=num_keyframes, # encoder block size\n",
    "    block_size_obs=block_size, # decoder block size\n",
    "    vocab_size=100,\n",
    "    n_tokens_per_frame=8, # n_tokens per image feature\n",
    "    feature_dim=1280, # image feature dimension\n",
    ")\n",
    "\n",
    "model = rt1_model.TOSIL(rt1_model.TOSILConfig(**model_args))\n",
    "model = model.to(device)\n",
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.ones(12, 5, 1280, 3, 3, device='cuda', dtype=torch.float32)\n",
    "Y = torch.ones(12, 1, 1280, 3, 3, device='cuda', dtype=torch.float32)\n",
    "actions = torch.ones(12, 4, device='cuda', dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/torchn/lib/python3.9/site-packages/torch/_functorch/aot_autograd.py:1251: UserWarning: Your compiler for AOTAutograd is returning a a function that doesn't take boxed arguments. Please wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. See https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "action_pred, loss = model(X, Y, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 4])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_pred.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOSIL Performance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rough_fun_timing(fun, *args, **kwargs):\n",
    "    start = time.time()\n",
    "    fun(*args, **kwargs)\n",
    "    end = time.time()\n",
    "    print(f\"Time taken: {(end - start) * 1000} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_step():\n",
    "    action_pred, loss = model(X, Y, actions)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rough_fun_timing(grad_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('torchn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7129dcc2f0dedf1e8cadafbc7dbe5e38e20b661608d098c252dd2423848ef4de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
