{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/user/Documents/projects/osil\")\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "import projects.metaworld.dataset as metaworld_dataset\n",
    "\n",
    "import utils.camera_utils_v2 as cu\n",
    "import sensors.point_cloud_sensor as pc_sensor\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "# for feature extraction and matching\n",
    "# from lightglue import LightGlue, SuperPoint, DISK\n",
    "import models.lightglue as lightglue_train_model\n",
    "import torch\n",
    "\n",
    "# torch.set_grad_enabled(False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 'mps', 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fbdbcfe8d00>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'projects.metaworld.dataset' from '/home/user/Documents/projects/osil/projects/metaworld/dataset.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(metaworld_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49]\n"
     ]
    }
   ],
   "source": [
    "EXCLUDED_ENV_IDS = [1,22,31,41,42]\n",
    "NUM_ENVS = 50\n",
    "\n",
    "env_ids = []\n",
    "for i in range(NUM_ENVS):\n",
    "    if i not in EXCLUDED_ENV_IDS:\n",
    "        env_ids.append(i)\n",
    "print(env_ids)\n",
    "\n",
    "dataset = metaworld_dataset.MetaworldFeatureMatchingDataset(\n",
    "    data_folder=\"/media/user/ssd2t/datasets2/metaworld_keyframes/all_envs\",\n",
    "    max_keypoints=50,\n",
    "    env_ids=env_ids,\n",
    "    eps=0.01,\n",
    "    dev=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.random.randint(0, len(dataset))\n",
    "img_0, img_1, depth_0, depth_1, seg_0, seg_1, match_data, kpts_0, kpts_1, dscpt_0, dscpt_1, matches_0, matches_1, assignment_mtr = dataset[s]\n",
    "# match_utils.visualize_matches_with_imgs(img_0.numpy(), img_1.numpy(), match_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightGlue(\n",
       "  (input_proj): Identity()\n",
       "  (posenc): LearnableFourierPositionalEncoding(\n",
       "    (Wr): Linear(in_features=2, out_features=32, bias=False)\n",
       "  )\n",
       "  (transformers): ModuleList(\n",
       "    (0-8): 9 x TransformerLayer(\n",
       "      (self_attn): SelfBlock(\n",
       "        (Wqkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "        (inner_attn): Attention()\n",
       "        (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): CrossBlock(\n",
       "        (to_qk): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (to_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (to_out): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (log_assignment): ModuleList(\n",
       "    (0-8): 9 x MatchAssignment(\n",
       "      (matchability): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (final_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (token_confidence): ModuleList(\n",
       "    (0-7): 8 x TokenConfidence(\n",
       "      (token): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "        (1): Sigmoid()\n",
       "      )\n",
       "      (loss_fn): BCEWithLogitsLoss()\n",
       "    )\n",
       "  )\n",
       "  (loss_fn): NLLLoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lightglue_train_model.LightGlue({})\n",
    "model.to(device)\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"keypoints0\": kpts_0[None].to(device),\n",
    "    \"descriptors0\": dscpt_0[None].to(device),\n",
    "    \"keypoints1\": kpts_1[None].to(device),\n",
    "    \"descriptors1\": dscpt_1[None].to(device),\n",
    "    \"view0\": {\n",
    "        \"image_size\": torch.Tensor([360, 480]).long().to(device)\n",
    "    },\n",
    "    \"view1\":{\n",
    "        \"image_size\": torch.Tensor([360, 480]).long().to(device)\n",
    "    },\n",
    "    \"gt_matches0\": matches_0[None].to(device),\n",
    "    \"gt_matches1\": matches_1[None].to(device),\n",
    "    \"gt_assignment\": assignment_mtr[None].to(device),\n",
    "}\n",
    "pred = model(data)\n",
    "losses, metrics = model.loss(pred, data)\n",
    "loss = torch.mean(losses[\"total\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['total', 'last', 'assignment_nll', 'nll_pos', 'nll_neg', 'num_matchable', 'num_unmatchable', 'confidence', 'row_norm'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'total': tensor([6.4842], device='cuda:0'),\n",
       "  'last': tensor([6.1328], device='cuda:0'),\n",
       "  'assignment_nll': tensor([6.1328], device='cuda:0'),\n",
       "  'nll_pos': tensor([11.0988], device='cuda:0'),\n",
       "  'nll_neg': tensor([1.1668], device='cuda:0'),\n",
       "  'num_matchable': tensor([7656.], device='cuda:0'),\n",
       "  'num_unmatchable': tensor([20.5000], device='cuda:0'),\n",
       "  'confidence': tensor([0.6971], device='cuda:0'),\n",
       "  'row_norm': tensor([0.3949], device='cuda:0')},\n",
       " {})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss[\"total\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
